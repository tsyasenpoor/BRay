{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import gzip\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment_data(instance_path):\n",
    "    dfs = {\n",
    "        \"pathways\": None,\n",
    "        \"statistics\": None,\n",
    "        \"train_stats\": None,\n",
    "        \"test_stats\": None, \n",
    "        \"val_stats\": None\n",
    "    }\n",
    "\n",
    "    if not os.path.isdir(instance_path):\n",
    "        print(f\"Error: Directory not found at {instance_path}\")\n",
    "        return tuple(dfs.values())\n",
    "\n",
    "    for filename in os.listdir(instance_path):\n",
    "        file_path = os.path.join(instance_path, filename)\n",
    "        \n",
    "        # Skip if not a file\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if 'analysis' in filename and filename.endswith('.json.gz'):\n",
    "                print(f\"Attempting to load {filename} (analysis JSON)...\")\n",
    "                with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                dfs['pathways'] = pd.DataFrame(data) \n",
    "                print(f\"Successfully created DataFrame for {filename}\")\n",
    "            elif 'results' in filename and filename.endswith('.json.gz'):\n",
    "                with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                if isinstance(data, dict):\n",
    "                    dfs['statistics'] = pd.DataFrame([data])\n",
    "                elif isinstance(data, list): \n",
    "                    dfs['statistics'] = pd.DataFrame(data)\n",
    "                else:\n",
    "                    print(f\"Warning: statistics file {filename} has an unexpected main data type: {type(data)}. Could not convert to DataFrame.\")\n",
    "            elif 'train' in filename and filename.endswith('.csv.gz'):\n",
    "                dfs['train_stats'] = pd.read_csv(file_path, compression='gzip')\n",
    "            elif 'test' in filename and filename.endswith('.csv.gz'):\n",
    "                dfs['test_stats'] = pd.read_csv(file_path, compression='gzip')\n",
    "            elif 'val' in filename and filename.endswith('.csv.gz'):\n",
    "                dfs['val_stats'] = pd.read_csv(file_path, compression='gzip')\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "    return dfs['pathways'], dfs['statistics'], dfs['train_stats'], dfs['test_stats'], dfs['val_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_path=\"/labs/Aguiar/SSPA_BRAY/BRay/Results/unmasked/20250523_122448\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f26823e6890>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/FCAM/tyasenpoor/miniconda3/envs/bray_cpu/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tst_pathways, tst_stats, tst_train, tst_test, tst_val = load_experiment_data(tst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def analyze_statistics(statistics_df):\n",
    "    row_data = statistics_df.iloc[0]\n",
    "    train_metrics=row_data['train_metrics']\n",
    "    test_metrics=row_data['test_metrics']\n",
    "    val_metrics=row_data['val_metrics']\n",
    "\n",
    "    metrics_list = [\n",
    "        {'set': 'train', 'metrics': train_metrics},\n",
    "        {'set': 'validation', 'metrics': val_metrics},\n",
    "        {'set': 'test', 'metrics': test_metrics}\n",
    "    ]\n",
    "    \n",
    "    metrics_df = pd.DataFrame([\n",
    "        {'Set': 'Train', **train_metrics},\n",
    "        {'Set': 'Validation', **val_metrics},\n",
    "        {'Set': 'Test', **test_metrics}\n",
    "    ])\n",
    "\n",
    "    print(\"Metrics Summary Table:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(metrics_df.to_string(index=False, float_format='%.4f'))\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(f\"\\nAvailable metrics: {list(train_metrics.keys())}\")\n",
    "    \n",
    "    return metrics_list, metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bray_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
